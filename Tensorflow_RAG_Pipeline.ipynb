{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b7d129cf97714ae58ad378564f12aaf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_514e848bcf3543e884a1dc06bc5eddd6",
              "IPY_MODEL_9f45d5aed687413f9907f719680cd0fa",
              "IPY_MODEL_8c7931dc9a404d86bb6e5e5c96443c39"
            ],
            "layout": "IPY_MODEL_55c75a9a1cce459e8d9048feab1f961c"
          }
        },
        "514e848bcf3543e884a1dc06bc5eddd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5747044b940541e4b844533beb2e389e",
            "placeholder": "​",
            "style": "IPY_MODEL_c92f348c9de94f23babb7a60b5ccfb80",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9f45d5aed687413f9907f719680cd0fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_585ca62578ad49c0989454bc2a5e4ad0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53a7dcb69f234d89a52a986c53c67d55",
            "value": 2
          }
        },
        "8c7931dc9a404d86bb6e5e5c96443c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0f39be8e12f402795e559abb83f9242",
            "placeholder": "​",
            "style": "IPY_MODEL_0a33260bbfcb45d0afb31ec872ebc668",
            "value": " 2/2 [01:46&lt;00:00, 52.15s/it]"
          }
        },
        "55c75a9a1cce459e8d9048feab1f961c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5747044b940541e4b844533beb2e389e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c92f348c9de94f23babb7a60b5ccfb80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "585ca62578ad49c0989454bc2a5e4ad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53a7dcb69f234d89a52a986c53c67d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0f39be8e12f402795e559abb83f9242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a33260bbfcb45d0afb31ec872ebc668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snehal-sd/RAG/blob/main/Tensorflow_RAG_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to NLP for RAG\n",
        "\n",
        "Thanks for coming! I've tried to include as many resources as possible, but the biggest part of this notebook is of course: the code!\n",
        "We'll run the main reccomended flow together, then build a RAG chatbot on a different set of data."
      ],
      "metadata": {
        "id": "2m4nASs4vl8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating and Using High-Quality Embeddings in RAG\n",
        "\n",
        "- Generate embeddings and use them to retrieve documents.\n",
        "- Generate text embeddings using Universal Sentence Encoder.\n",
        "- Implement FAISS for fast nearest-neighbor search.\n",
        "- Re-rank to improve retrieval quality in RAG.\n",
        "\n",
        "---\n",
        "\n",
        "- **Embeddings** convert text into **high-dimensional numerical vectors** that capture meaning.\n",
        "- They allow machines to **compare text meaning mathematically** instead of relying on exact words.\n",
        "- Used in **search engines, chatbots, and RAG systems**.\n",
        "\n",
        "📌 **Alternatives:**\n",
        "- [`intfloat/e5-large-v2`](https://huggingface.co/intfloat/e5-large-v2) – Another top-tier embedding model.\n",
        "- [`sentence-transformers/all-mpnet-base-v2`](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) – More lightweight option.\n",
        "\n",
        "🧘☸️ **All This Will Change**\n",
        "- The only thing constant in AI is change- be [ready to re-run evaluations](https://github.com/RUC-NLPIR/FlashRAG)\n",
        "- [Code Embeddings Eval](https://github.com/CoIR-team/coir)\n"
      ],
      "metadata": {
        "id": "c38GOT1vxcB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Install Dependencies"
      ],
      "metadata": {
        "id": "wqdFXzul48YT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngnAgoyXveJS",
        "outputId": "6bee9089-771e-4c78-ea11-8cb4719c4673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from wikipedia-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install wikipedia-api"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1.5: Fetch some documents from Wikipedia"
      ],
      "metadata": {
        "id": "l-AyJWkWxj35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipediaapi\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Set up Wikipedia API with a custom User-Agent\n",
        "wiki_wiki = wikipediaapi.Wikipedia(user_agent='MyResearchBot/1.0 (https://themultiverse.school/; liz@themultiverse.school)', language='en')\n",
        "\n",
        "# Define categories and sample articles from different domains\n",
        "categories = {\n",
        "  \"Computers\": {\n",
        "      \"Computer science\": [\"Abstract Data Structure\", \"Algorithm\", \"Object Oriented Programming\", \"Scripting\", \"Python (programming language)\"],\n",
        "      \"CyberSecurity\": [\"TCP IP\", \"Internet Protocol\", \"Computer Network\", \"TCP Packet\", \"LoRA\", \"OSI Model\", \"Layer 1\", \"Layer 2\", \"Layer 3\", \"Layer 4\", \"Layer 5\", \"Layer 6\", \"Layer 7\", \"Layer 8\", \"International Organization for Standardization\", \"OSHA\"],\n",
        "      \"Machine Learning\": [\"Artificial intelligence\", \"Machine learning\", \"Deep learning\", \"Computer vision\", \"Natural language processing\", \"FAISS\", \"Embedding\"]\n",
        "  },\n",
        "  \"Biology\": {\n",
        "    \"Cell biology\": [\"Cytoskeleton\", \"Cell membrane\", \"Endoplasmic reticulum\", \"Golgi apparatus\", \"Apoptosis\"],\n",
        "    \"Genetics\": [\"Epigenetics\", \"Gene expression\", \"CRISPR\", \"DNA replication\", \"Genetic drift\"],\n",
        "    \"Food Web\": [\"Trophic cascade\", \"Keystone species\", \"Ecological pyramid\", \"Energy flow (ecology)\", \"Biogeochemical cycle\"],\n",
        "    \"Microbiology\": [\"Bacteriophage\", \"Gram-positive bacteria\", \"Archaea\", \"Biofilm\", \"Extremophiles\"],\n",
        "    \"Human anatomy\": [\"Circulatory system\", \"Endocrine system\", \"Nervous system\", \"Musculoskeletal system\", \"Digestive system\"],\n",
        "    \"Mitochondria\": [\"ATP synthase\", \"Mitochondrial DNA\", \"Oxidative phosphorylation\", \"Mitochondrial diseases\", \"Endosymbiotic theory\"],\n",
        "    \"Phylogenetics\": [\"Cladistics\", \"Evolutionary tree\", \"Molecular phylogenetics\", \"Common descent\", \"Homology (biology)\"]\n",
        "  },\n",
        "  \"Chemistry\": {\n",
        "    \"Organic chemistry\": [\"Functional groups\", \"Alkene\", \"Aromaticity\", \"Polymerization\", \"Carbohydrates\"],\n",
        "    \"Inorganic chemistry\": [\"Coordination complex\", \"Transition metal\", \"Crystallography\", \"Lanthanides\", \"Actinides\"],\n",
        "    \"Analytical chemistry\": [\"Chromatography\", \"Spectroscopy\", \"Mass spectrometry\", \"Electrochemical analysis\", \"Nuclear magnetic resonance\"],\n",
        "    \"Physical chemistry\": [\"Quantum chemistry\", \"Thermodynamics\", \"Statistical mechanics\", \"Chemical kinetics\", \"Molecular dynamics\"],\n",
        "    \"Biochemistry\": [\"Enzyme kinetics\", \"Protein folding\", \"Lipid metabolism\", \"Glycolysis\", \"Signal transduction\"]\n",
        "  },\n",
        "  \"Geology\": {\n",
        "    \"Plate tectonics\": [\"Subduction zone\", \"Mid-ocean ridge\", \"Continental drift\", \"Transform fault\", \"Rift valley\"],\n",
        "    \"Mineralogy\": [\"Silicate minerals\", \"Feldspar\", \"Quartz\", \"Mohs scale of mineral hardness\", \"Crystal habit\"],\n",
        "    \"Volcano\": [\"Stratovolcano\", \"Shield volcano\", \"Pyroclastic flow\", \"Volcanic explosivity index\", \"Supervolcano\"],\n",
        "    \"Earthquake\": [\"Seismic wave\", \"Richter scale\", \"Fault mechanics\", \"Liquefaction\", \"Tsunami\"],\n",
        "    \"Geological history of Earth\": [\"Hadean eon\", \"Cambrian explosion\", \"Snowball Earth\", \"K-Pg extinction event\", \"Great Oxygenation Event\"],\n",
        "    \"Igneous Rock\": [\"Basalt\", \"Granite\", \"Magma differentiation\", \"Intrusive rock\", \"Plutonic rock\"]\n",
        "  },\n",
        "  \"History\": {\n",
        "    \"World War II\": [\"Battle of Stalingrad\", \"Manhattan Project\", \"D-Day\", \"Holocaust\", \"Blitzkrieg\"],\n",
        "    \"Ancient Egypt\": [\"Pharaoh\", \"Hieroglyphics\", \"Valley of the Kings\", \"Mummification\", \"Great Pyramid of Giza\"],\n",
        "    \"Renaissance\": [\"Humanism (Renaissance)\", \"Leonardo da Vinci\", \"Medici family\", \"Florence during the Renaissance\", \"Printing press\"],\n",
        "    \"Industrial Revolution\": [\"Steam engine\", \"Factory system\", \"Textile industry\", \"Urbanization\", \"Luddites\"],\n",
        "    \"Cold War\": [\"Cuban Missile Crisis\", \"Space Race\", \"Berlin Wall\", \"McCarthyism\", \"NATO\"]\n",
        "  },\n",
        "  \"Art\": {\n",
        "    \"Impressionism\": [\"Claude Monet\", \"Edgar Degas\", \"Pierre-Auguste Renoir\", \"Plein air painting\", \"Color theory\"],\n",
        "    \"Cubism\": [\"Pablo Picasso\", \"Georges Braque\", \"Analytic Cubism\", \"Synthetic Cubism\", \"Still Life with Chair Caning\"],\n",
        "    \"Renaissance art\": [\"Michelangelo\", \"Sistine Chapel ceiling\", \"Raphael\", \"Leonardo da Vinci’s notebooks\", \"Linear perspective\"],\n",
        "    \"Sculpture\": [\"Rodin\", \"Bronze casting\", \"Marble sculpture\", \"Gothic sculpture\", \"Greek classical sculpture\"],\n",
        "    \"Abstract art\": [\"Wassily Kandinsky\", \"Color field painting\", \"Abstract expressionism\", \"Suprematism\", \"De Stijl\"],\n",
        "    \"Dadaism\": [\"Marcel Duchamp\", \"Readymades\", \"Cabaret Voltaire\", \"Tristan Tzara\", \"Anti-art movement\"],\n",
        "    \"Absurdism\": [\"Albert Camus\", \"The Myth of Sisyphus\", \"Theatre of the Absurd\", \"Samuel Beckett\", \"Waiting for Godot\"]\n",
        "  }\n",
        "}\n",
        "\n",
        "# Create the cache directory\n",
        "cache_dir = \"data/wikipedia_cache\"\n",
        "os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "# Function to save Wikipedia text to cache\n",
        "def save_to_cache(title, text):\n",
        "    filename = os.path.join(cache_dir, f\"{title.replace(' ', '_')}.txt\")\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text)\n",
        "\n",
        "# Function to load Wikipedia text from cache\n",
        "def load_from_cache(title):\n",
        "    filename = os.path.join(cache_dir, f\"{title.replace(' ', '_')}.txt\")\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
        "            return file.read()\n",
        "    return None\n",
        "\n",
        "# Function to fetch Wikipedia page content with caching\n",
        "def get_wikipedia_text(title):\n",
        "    # Check if the page is already cached\n",
        "    cached_text = load_from_cache(title)\n",
        "    if cached_text:\n",
        "        return cached_text\n",
        "\n",
        "    page = wiki_wiki.page(title)\n",
        "\n",
        "    # If it's a disambiguation page, follow the first few linked pages\n",
        "    if page.exists():\n",
        "        if \"may refer to:\" in page.text[:200]:  # Check if it's a disambiguation page\n",
        "            linked_pages = list(page.links.keys())[:5]  # Grab first few related links\n",
        "            for linked_title in linked_pages:\n",
        "                sub_page = wiki_wiki.page(linked_title)\n",
        "                if sub_page.exists() and len(sub_page.text) > 500:  # Ensure meaningful content\n",
        "                    save_to_cache(linked_title, sub_page.text[:2000])  # Save to cache\n",
        "                    return sub_page.text[:2000]\n",
        "\n",
        "        # Save the fetched page to cache and return it\n",
        "        save_to_cache(title, page.text[:2000])\n",
        "        return page.text[:2000]\n",
        "\n",
        "    return None\n",
        "\n",
        "# Function to get additional Wikipedia pages from related categories\n",
        "def get_category_pages(category_name, max_pages=5):\n",
        "    category_page = wiki_wiki.page(f\"Category:{category_name}\")\n",
        "    pages = []\n",
        "\n",
        "    if category_page.exists():\n",
        "        for title, page in category_page.categorymembers.items():\n",
        "            if page.ns == 0:  # Only fetch articles (not subcategories)\n",
        "                text = get_wikipedia_text(title)\n",
        "                if text:\n",
        "                    pages.append(text)\n",
        "                if len(pages) >= max_pages:\n",
        "                    break\n",
        "    return pages\n",
        "\n",
        "# Fetch and store documents\n",
        "documents = []\n",
        "\n",
        "for category, topics in categories.items():\n",
        "    for topic in topics:\n",
        "        print(\"Getting \", topic)\n",
        "        for page in topics[topic]:\n",
        "            text = get_wikipedia_text(page)\n",
        "            if text:\n",
        "                documents.append(text)\n",
        "\n",
        "    # Also pull a few pages from the Wikipedia category\n",
        "    documents.extend(get_category_pages(category, max_pages=5))\n",
        "\n",
        "\n",
        "print(f\"Collected {len(documents)} Wikipedia documents. Cached files saved in: {cache_dir}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_zcmQY7xFtY",
        "outputId": "202f7a55-96a0-4ec7-8968-f4380ee48ea5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting  Computer science\n",
            "Getting  CyberSecurity\n",
            "Getting  Machine Learning\n",
            "Getting  Cell biology\n",
            "Getting  Genetics\n",
            "Getting  Food Web\n",
            "Getting  Microbiology\n",
            "Getting  Human anatomy\n",
            "Getting  Mitochondria\n",
            "Getting  Phylogenetics\n",
            "Getting  Organic chemistry\n",
            "Getting  Inorganic chemistry\n",
            "Getting  Analytical chemistry\n",
            "Getting  Physical chemistry\n",
            "Getting  Biochemistry\n",
            "Getting  Plate tectonics\n",
            "Getting  Mineralogy\n",
            "Getting  Volcano\n",
            "Getting  Earthquake\n",
            "Getting  Geological history of Earth\n",
            "Getting  Igneous Rock\n",
            "Getting  World War II\n",
            "Getting  Ancient Egypt\n",
            "Getting  Renaissance\n",
            "Getting  Industrial Revolution\n",
            "Getting  Cold War\n",
            "Getting  Impressionism\n",
            "Getting  Cubism\n",
            "Getting  Renaissance art\n",
            "Getting  Sculpture\n",
            "Getting  Abstract art\n",
            "Getting  Dadaism\n",
            "Getting  Absurdism\n",
            "Collected 200 Wikipedia documents. Cached files saved in: data/wikipedia_cache\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Encode Embeddings with TensorFlow Universal Sentence Encoder\n",
        "If you prefer a TensorFlow-based approach, you can use Universal Sentence Encoder.\n"
      ],
      "metadata": {
        "id": "-gUf2lOkxr8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load USE model\n",
        "use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "# Generate embeddings\n",
        "document_embeddings = use_model(documents)"
      ],
      "metadata": {
        "id": "AmEJIQVKxUPM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = input(\"Enter a question: \")"
      ],
      "metadata": {
        "id": "AZhB3yDiitb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9948bcbb-3a88-41b7-deeb-c003e6db0ea1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a question: What are the contributions of Claude Monet to the world?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Similarity (several methods)\n",
        "\n",
        "#### TensorFlow Approximate Nearest Neighbors (ANN)\n",
        "\n",
        "| Feature            | **FAISS** (Facebook AI Similarity Search) | **General ANN Methods** (e.g., HNSW, BallTree, KDTree) |\n",
        "|-------------------|----------------------------------|--------------------------------|\n",
        "| **Speed**        | Highly optimized for fast search, supports GPU acceleration | Varies by method; HNSW is fast, but KDTree struggles in high dimensions |\n",
        "| **Scalability**  | Handles millions to billions of vectors efficiently | Some ANN methods scale well (HNSW), others (KDTree, BallTree) do not |\n",
        "| **Accuracy**     | Configurable for exact or approximate search | Varies; HNSW offers high accuracy, others may sacrifice accuracy for speed |\n",
        "| **Memory Usage** | Optimized via quantization and compression | Varies; HNSW uses more memory, others may be more efficient |\n",
        "| **Implementation Complexity** | Easy-to-use library with multiple indexing strategies | Some methods require deeper parameter tuning and domain expertise |\n",
        "| **Parallelization** | Supports multi-threading and GPU acceleration | Many ANN methods lack GPU support |\n",
        "| **Use Case Fit** | Best for large-scale, high-dimensional similarity search | Some ANN methods (KDTree, BallTree) perform better in low dimensions |\n"
      ],
      "metadata": {
        "id": "1xVItl8hyQA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "# Create a FAISS index\n",
        "dimension = document_embeddings.shape[1]  # Get dimension from your embeddings\n",
        "index = faiss.IndexFlatL2(dimension)  # L2 distance index\n",
        "\n",
        "# Convert embeddings to numpy float32 array if not already\n",
        "embeddings_np = np.array(document_embeddings).astype(np.float32)\n",
        "\n",
        "# Add vectors to the index\n",
        "index.add(embeddings_np)"
      ],
      "metadata": {
        "id": "lT6Ykpzwzl2q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Using Embeddings for Retrieval\n",
        "\n",
        "Now, let’s query the knowledge base using FAISS and find the most relevant documents"
      ],
      "metadata": {
        "id": "5rEqwDvbyZpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to retrieve top-k documents\n",
        "def retrieve_top_k_documents(query, top_k=3):\n",
        "    query_embedding = use_model([query])\n",
        "    ## convert to numpy array\n",
        "    query_embedding = np.array(query_embedding).astype(np.float32)\n",
        "    _, indices = index.search(query_embedding, top_k)\n",
        "    return [documents[i] for i in indices[0]]\n",
        "\n",
        "retrieved_docs = retrieve_top_k_documents(query, 5)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nTop Retrieved Documents:\")\n",
        "for idx, doc in enumerate(retrieved_docs, 1):\n",
        "    print(f\"{idx}. {doc}\")"
      ],
      "metadata": {
        "id": "YZKQqeoty0TE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d098477f-74ab-4019-e112-138da8f488a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top Retrieved Documents:\n",
            "1. Cubism is an early-20th-century avant-garde art movement begun in Paris that revolutionized painting and the visual arts, and influenced artistic innovations in music, ballet, literature, and architecture. Cubist subjects are analyzed, broken up, and reassembled in an abstract form—instead of depicting objects from a single perspective, the artist depicts the subject from multiple perspectives to represent the subject in a greater context. Cubism has been considered the most influential art movement of the 20th century. The term cubism is broadly associated with a variety of artworks produced in Paris (Montmartre and Montparnasse) or near Paris (Puteaux) during the 1910s and throughout the 1920s.\n",
            "The movement was pioneered in partnership by Pablo Picasso and Georges Braque, and joined by Jean Metzinger, Albert Gleizes, Robert Delaunay, Henri Le Fauconnier, Juan Gris, and Fernand Léger. One primary influence that led to Cubism was the representation of three-dimensional form in the late works of Paul Cézanne. A retrospective of Cézanne's paintings was held at the Salon d'Automne of 1904, current works were displayed at the 1905 and 1906 Salon d'Automne, followed by two commemorative retrospectives after his death in 1907.\n",
            "In France, offshoots of Cubism developed, including Orphism, abstract art and later Purism. The impact of Cubism was far-reaching and wide-ranging in the arts and in popular culture. Cubism introduced collage as a modern art form. In France and other countries Futurism, Suprematism, Dada, Constructivism, De Stijl and Art Deco developed in response to Cubism. Early Futurist paintings hold in common with Cubism the fusing of the past and the present, the representation of different views of the subject pictured at the same time or successively, also called multiple perspective, simultaneity or multiplicity, while Constructivism was influenced by Picasso's technique of constructing sculpture from separate elements. Other common threads between these di\n",
            "2. Cubism is an early-20th-century avant-garde art movement begun in Paris that revolutionized painting and the visual arts, and influenced artistic innovations in music, ballet, literature, and architecture. Cubist subjects are analyzed, broken up, and reassembled in an abstract form—instead of depicting objects from a single perspective, the artist depicts the subject from multiple perspectives to represent the subject in a greater context. Cubism has been considered the most influential art movement of the 20th century. The term cubism is broadly associated with a variety of artworks produced in Paris (Montmartre and Montparnasse) or near Paris (Puteaux) during the 1910s and throughout the 1920s.\n",
            "The movement was pioneered in partnership by Pablo Picasso and Georges Braque, and joined by Jean Metzinger, Albert Gleizes, Robert Delaunay, Henri Le Fauconnier, Juan Gris, and Fernand Léger. One primary influence that led to Cubism was the representation of three-dimensional form in the late works of Paul Cézanne. A retrospective of Cézanne's paintings was held at the Salon d'Automne of 1904, current works were displayed at the 1905 and 1906 Salon d'Automne, followed by two commemorative retrospectives after his death in 1907.\n",
            "In France, offshoots of Cubism developed, including Orphism, abstract art and later Purism. The impact of Cubism was far-reaching and wide-ranging in the arts and in popular culture. Cubism introduced collage as a modern art form. In France and other countries Futurism, Suprematism, Dada, Constructivism, De Stijl and Art Deco developed in response to Cubism. Early Futurist paintings hold in common with Cubism the fusing of the past and the present, the representation of different views of the subject pictured at the same time or successively, also called multiple perspective, simultaneity or multiplicity, while Constructivism was influenced by Picasso's technique of constructing sculpture from separate elements. Other common threads between these di\n",
            "3. Leonardo di ser Piero da Vinci (15 April 1452 – 2 May 1519) was an Italian polymath of the High Renaissance who was active as a painter, draughtsman, engineer, scientist, theorist, sculptor, and architect. While his fame initially rested on his achievements as a painter, he has also become known for his notebooks, in which he made drawings and notes on a variety of subjects, including anatomy, astronomy, botany, cartography, painting, and palaeontology. Leonardo is widely regarded to have been a genius who epitomised the Renaissance humanist ideal, and his collective works comprise a contribution to later generations of artists matched only by that of his younger contemporary Michelangelo.\n",
            "Born out of wedlock to a successful notary and a lower-class woman in, or near, Vinci, he was educated in Florence by the Italian painter and sculptor Andrea del Verrocchio. He began his career in the city, but then spent much time in the service of Ludovico Sforza in Milan. Later, he worked in Florence and Milan again, as well as briefly in Rome, all while attracting a large following of imitators and students. Upon the invitation of Francis I, he spent his last three years in France, where he died in 1519. Since his death, there has not been a time where his achievements, diverse interests, personal life, and empirical thinking have failed to incite interest and admiration, making him a frequent namesake and subject in culture.\n",
            "Leonardo is identified as one of the greatest painters in the history of Western art and is often credited as the founder of the High Renaissance. Despite having many lost works and fewer than 25 attributed major works – including numerous unfinished works – he created some of the most influential paintings in the Western canon. The Mona Lisa is his best known work and is the world's most famous individual painting. The Last Supper is the most reproduced religious painting of all time and his Vitruvian Man drawing is also regarded as a cultural icon. In 2\n",
            "4. Oscar-Claude Monet (UK: , US: ; French: [klod mɔnɛ]; 14 November 1840 – 5 December 1926) was a French painter and founder of Impressionism painting who is seen as a key precursor to modernism, especially in his attempts to paint nature as he perceived it. During his long career, he was the most consistent and prolific practitioner of Impressionism's philosophy of expressing one's perceptions of nature, especially as applied to plein air (outdoor) landscape painting. The term \"Impressionism\" is derived from the title of his painting Impression, soleil levant, which was first exhibited in the so-called \"exhibition of rejects\" of 1874–an exhibition initiated by Monet and like-minded artists as an alternative to the Salon.\n",
            "Monet was raised in Le Havre, Normandy, and became interested in the outdoors and drawing from an early age. Although his mother, Louise-Justine Aubrée Monet, supported his ambitions to be a painter, his father, Claude-Adolphe, disapproved and wanted him to pursue a career in business. He was very close to his mother, but she died in January 1857 when he was sixteen years old, and he was sent to live with his childless, widowed but wealthy aunt, Marie-Jeanne Lecadre. He went on to study at the Académie Suisse, and under the academic history painter Charles Gleyre, where he was a classmate of Auguste Renoir. His early works include landscapes, seascapes, and portraits, but attracted little attention. A key early influence was Eugène Boudin, who introduced him to the concept of plein air painting. From 1883, Monet lived in Giverny, also in northern France, where he purchased a house and property and began a vast landscaping project, including a water-lily pond.\n",
            "Monet's ambition to document the French countryside led to a method of painting the same scene many times so as to capture the changing of light and the passing of the seasons. Among the best-known examples are his series of haystacks (1890–1891), paintings of Rouen Cathedral (1892–1894), and the\n",
            "5. Pablo Ruiz Picasso (25 October 1881 – 8 April 1973) was a Spanish painter, sculptor, printmaker, ceramicist, and theatre designer who spent most of his adult life in France. One of the most influential artists of the 20th century, he is known for co-founding the Cubist movement, the invention of constructed sculpture, the co-invention of collage, and for the wide variety of styles that he helped develop and explore. Among his most famous works are the proto-Cubist Les Demoiselles d'Avignon (1907) and the anti-war painting Guernica (1937), a dramatic portrayal of the bombing of Guernica by German and Italian air forces during the Spanish Civil War.\n",
            "Picasso demonstrated extraordinary artistic talent in his early years, painting in a naturalistic manner through his childhood and adolescence. During the first decade of the 20th century, his style changed as he experimented with different theories, techniques, and ideas. After 1906, the Fauvist work of the older artist Henri Matisse motivated Picasso to explore more radical styles, beginning a fruitful rivalry between the two artists, who subsequently were often paired by critics as the leaders of modern art.\n",
            "Picasso's output, especially in his early career, is often periodized. While the names of many of his later periods are debated, the most commonly accepted periods in his work are the Blue Period (1901–1904), the Rose Period (1904–1906), the African-influenced Period (1907–1909), Analytic Cubism (1909–1912), and Synthetic Cubism (1912–1919), also referred to as the Crystal period. Much of Picasso's work of the late 1910s and early 1920s is in a neoclassical style, and his work in the mid-1920s often has characteristics of Surrealism. His later work often combines elements of his earlier styles.\n",
            "Exceptionally prolific throughout the course of his long life, Picasso achieved universal renown and immense fortune for his revolutionary artistic accomplishments, and became one of the best-known figures in 20th-century art\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Re-Ranking: Use a Neural Re-Ranker to Improve Retrieval Precision\n",
        "\n",
        "Problem: The retrieved documents may not always be perfectly ranked.\n",
        "Solution: Re-rank the results!"
      ],
      "metadata": {
        "id": "i4eq9drEy5S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from transformers import TFBertModel, BertTokenizer\n",
        "\n",
        "# Load Pretrained Transformer Model (BERT for ranking)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "class RankingModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(RankingModel, self).__init__()\n",
        "        self.bert = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.score_layer = tf.keras.layers.Dense(1, activation=\"linear\")\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        input_ids, attention_mask = inputs\n",
        "        bert_outputs = self.bert(input_ids, attention_mask=attention_mask, training=training)\n",
        "        pooled_output = bert_outputs.pooler_output\n",
        "        scores = self.score_layer(pooled_output)\n",
        "        return scores\n",
        "\n",
        "def tokenize_texts(texts, max_length=128):\n",
        "    \"\"\"Tokenizes and converts texts into BERT input format.\"\"\"\n",
        "    encodings = tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"tf\"\n",
        "    )\n",
        "    return encodings[\"input_ids\"], encodings[\"attention_mask\"]\n",
        "\n",
        "def rerank_documents(query, retrieved_docs):\n",
        "    \"\"\"Re-ranks documents based on query relevance using BERT.\"\"\"\n",
        "    # Create pairs of query and each document\n",
        "    pairs = [f\"{query} [SEP] {doc}\" for doc in retrieved_docs]\n",
        "\n",
        "    # Tokenize all pairs\n",
        "    input_ids, attention_mask = tokenize_texts(pairs)\n",
        "\n",
        "    # Build and use the ranking model\n",
        "    ranking_model = RankingModel()\n",
        "\n",
        "    # Get scores by passing through the model\n",
        "    scores = ranking_model([input_ids, attention_mask], training=False).numpy().flatten()\n",
        "\n",
        "    # Return re-ranked documents\n",
        "    ranked_indices = np.argsort(-scores)  # Sort in descending order\n",
        "    reranked_docs = [retrieved_docs[i] for i in ranked_indices]\n",
        "\n",
        "    return reranked_docs\n",
        "\n",
        "\n",
        "\n",
        "# Apply Re-Ranking\n",
        "reranked_docs = rerank_documents(query, retrieved_docs)\n",
        "\n",
        "# Display Results\n",
        "print(\"\\nTop Re-Ranked Documents:\")\n",
        "for idx, doc in enumerate(reranked_docs, 1):\n",
        "    print(f\"{idx}. {doc}\")"
      ],
      "metadata": {
        "id": "lWUuzp9tzINE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise: Implement a Simple RAG-Based Q&A System, then compare models\n",
        "\n",
        "Objective\n",
        "\n",
        "Students will:\n",
        "1.\tUse wikipedia articles as the basis for your RAG system.\n",
        "2.\tUse BERT embeddings to create a FAISS index of the documents. Compare HNSW and non-HNSW versions.\n",
        "3.\tAccept queries and retrieve the best documents to answer the question.\n",
        "4.\tUse a Neural Reranker to re-rank results retrieved.\n",
        "5.  Use [Deepseek's R1-Distillation of Qwen](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B) to interpret the retrieved documents into an answer to your question (or an internally-hosted LLM of your choice)"
      ],
      "metadata": {
        "id": "MvOthstwygR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Using groq - generate and use groq key\n",
        "!pip install groq"
      ],
      "metadata": {
        "id": "oSVO-ZsKj5J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## here's where your code goes\n",
        "## given the context and the user query\n",
        "## generate a response using a language model\n",
        "from google.colab import userdata\n",
        "groq_key = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key=groq_key)\n",
        "\n",
        "prompt = \"Using the context above, answer the user's query:\"\n",
        "context = \"\\n\".join([doc for docs in reranked_docs])\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{context}  {prompt}  {query}\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"deepseek-r1-distill-qwen-32b\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "nYo8FZ6hj7PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly from HuggingFace\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n"
      ],
      "metadata": {
        "id": "P-oXn3jNM-1z",
        "outputId": "2c28453d-289e-4d50-8a61-05a994da691c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b7d129cf97714ae58ad378564f12aaf8",
            "514e848bcf3543e884a1dc06bc5eddd6",
            "9f45d5aed687413f9907f719680cd0fa",
            "8c7931dc9a404d86bb6e5e5c96443c39",
            "55c75a9a1cce459e8d9048feab1f961c",
            "5747044b940541e4b844533beb2e389e",
            "c92f348c9de94f23babb7a60b5ccfb80",
            "585ca62578ad49c0989454bc2a5e4ad0",
            "53a7dcb69f234d89a52a986c53c67d55",
            "b0f39be8e12f402795e559abb83f9242",
            "0a33260bbfcb45d0afb31ec872ebc668"
          ]
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7d129cf97714ae58ad378564f12aaf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(question, documents, max_length=512):\n",
        "    # Combine question and documents into a single prompt\n",
        "    prompt = f\"Question: {question}\\nDocuments:\\n\" + \"\\n\".join(documents) + \"\\nAnswer:\"\n",
        "\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
        "\n",
        "    # Move to the correct device\n",
        "    input_ids = inputs[\"input_ids\"].to(model.device)\n",
        "\n",
        "    # Generate response\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(input_ids, max_length=max_length, temperature=0.7, top_p=0.9)\n",
        "\n",
        "    # Decode response\n",
        "    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "17Xla_VfSRRI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the contribution of Claude Monet to the world?\"\n",
        "documents = context = \"\\n\".join([doc for docs in reranked_docs])\n",
        "\n",
        "answer = generate_answer(question, documents)\n",
        "print(\"Generated Answer:\\n\", answer)"
      ],
      "metadata": {
        "id": "a4Ly6ZY3Sg4v",
        "outputId": "cb06a4b7-6013-45de-a0aa-3682f2da3ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-60025fdc3def>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generated Answer:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-7574547aaf90>\u001b[0m in \u001b[0;36mgenerate_answer\u001b[0;34m(question, documents, max_length)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Tokenize input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Move to the correct device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hierarchical Navigable Small Worlds (HNSW) Indexing\n",
        "Hierarchical Navigable Small Worlds (HNSW) Indexing\n",
        "\n",
        "What is HNSW?\n",
        "\n",
        "HNSW (Hierarchical Navigable Small Worlds) is an advanced approximate nearest neighbor (ANN) algorithm that speeds up retrieval while maintaining high accuracy. Unlike FAISS IndexFlatL2, it builds a multi-layered graph for efficient navigation.\n",
        "\n",
        "How It Works\n",
        "- Hierarchical Structure: Vectors are arranged in layers; the top has fewer nodes, lower layers have more.\n",
        "- Graph-Based Navigation: Each point connects to neighbors, forming a graph. Searches:\n",
        "- Start at a random top-layer entry\n",
        "- Navigate toward the query\n",
        "- Descend layers for precision\n",
        "- Small World Properties: Most nodes are reachable in a few steps.\n",
        "\n",
        "Advantages Over Flat Indexing\n",
        "- **Scalability**: Handles millions of vectors with sub-linear search time; flat indices are linear.\n",
        "- **Speed-Accuracy Trade-off**: Tunable via `M` and `ef_construction`.\n",
        "- **Memory Efficiency**: More efficient than a full linear scan despite higher memory use.\n",
        "- **Real-World Performance**: Outperforms many ANN algorithms when properly tuned.\n",
        "\n",
        "When to Use HNSW\n",
        "- Dataset >10,000 documents\n",
        "- Query speed is critical\n",
        "- High recall accuracy (>95%) needed without a full scan\n",
        "- Sufficient memory available for graph storage"
      ],
      "metadata": {
        "id": "Al2NOJL1zHw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "# Create HNSW index\n",
        "embedding_size = document_embeddings.shape[1]  # 1024 for BGE-large-en\n",
        "M = 16  # Number of connections per layer (higher = more accurate but slower to build)\n",
        "ef_construction = 200  # Controls index quality (higher = better recall but slower to build)\n",
        "\n",
        "# Create the index\n",
        "index = faiss.IndexHNSWFlat(embedding_size, M)\n",
        "index.hnsw.efConstruction = ef_construction\n",
        "index.hnsw.efSearch = 128  # Controls search accuracy/speed trade-off\n",
        "\n",
        "# Add vectors to the index\n",
        "index.add(document_embeddings)"
      ],
      "metadata": {
        "id": "UbXqYP0W1ydw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}